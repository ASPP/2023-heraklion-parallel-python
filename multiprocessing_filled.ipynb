{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "179af4aa",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## The builtin `multiprocessing` module\n",
    "\n",
    "Jakob will introduce the builtin `multiprocessing` module, which allows you to simply parallelize work in Python.\n",
    "\n",
    "Here, we will only consider embarassingly parallel problems (more on that in a second)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bda58b0",
   "metadata": {},
   "source": [
    "# Serial Python\n",
    "\n",
    "Before we get into parallel processing, let's first consider how the type of problems we'll consider are typically solved in a serial context. We'll focus on problems which always have the following form: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e06fd89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "def do_science(x):\n",
    "    \"\"\"For example:\n",
    "    - training a neural network (hyperparameter tuning!)\n",
    "    - getting results from a database\n",
    "    - scraping some websites\n",
    "    - reading files\n",
    "    - sampling monte-carlo style\n",
    "    \"\"\"\n",
    "    return x ** 2  # we don't really do anything ;)\n",
    "\n",
    "results = []\n",
    "input_data = range(10)\n",
    "for x in input_data:\n",
    "    results.append(do_science(x))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e17e454",
   "metadata": {},
   "source": [
    "This typical structure (or \"smell\") is pretty common and most likely all of you have something similar somewhere in your code. It's an excellent opportunity for leveraging parallelism to speed things up. However, first we'll rewrite this code using the builtin `map` function, it makes the code more compact and it will be easier to make this run in parallel. `map` takes a function and an iterable and applies the function to each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ed56dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "# when applying a function to a bunch of data, maybe you would use list comprehension\n",
    "results = [do_science(x) for x in input_data]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb2369bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "# however, here we use map to later use its parallel implementations\n",
    "results = map(do_science, input_data)\n",
    "results = list(results)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6bcf98",
   "metadata": {},
   "source": [
    "(watch out: `map` returns a generator, you need to \"exhaust it\" (convert it to a list) explicitly)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9437e391",
   "metadata": {},
   "source": [
    "### Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3210a313",
   "metadata": {},
   "source": [
    "## Exercise 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c245d50d",
   "metadata": {},
   "source": [
    "Questions:\n",
    "- Can we also compute the *sum* of numbers `0..9` using map? -> no(t trivially). results of operations depend on each other. this is a contra-indicator for \"embarrassingly parallel\" problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2da038",
   "metadata": {},
   "source": [
    "# Embarassingly parallel Python\n",
    "This type of problem is referred to as \"embarrassingly parallel\" problems. This indicates that they can be easily parallelized across threads or processes as they do not require interaction while running (they can also be run in serial!). For these types of problems, we can use the builtin `multiprocessing` module. It supports parallel versions of `map` which can be run in parallel processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c72c20",
   "metadata": {},
   "source": [
    "## Parallel threads\n",
    "We first work with the `ThreadPool` available from the `multiprocessing.pool` module. We assume CPython in which the GIL prevent several threads from executing in parallel. However, for some use cases, in particular those which are **I/O bound**, threading can be very useful. Consider for example obtaining data from some database: you would like to query a couple of measurements, and completing each of these queries may take some processing time on the server. Here we mimick this server-side processing time by merely sleeping (which releases the GIL)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942a6d81",
   "metadata": {},
   "source": [
    "Now, we use use `ThreadPool` do perform these queries using multiple threads (here the `processes` argument actually refers to the number of threads).\n",
    "\n",
    "First, let's figure out how many CPUs we have available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83fa715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee690f7",
   "metadata": {},
   "source": [
    "# Thread-parallel(?) number crunching\n",
    "Now let's consider a compute-intense number-crunching task, for example tuning hyperparameters our fancy neural network model to squeeze out the additional 0.0002% increase in accuracy. Here we mimick the training by merely counting down from a large number (let's avoid cognitive overhead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ba15f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(x):\n",
    "    \"\"\"'Train' your favourite neural network model.\"\"\"\n",
    "    print(f'training with {x} start')\n",
    "    n = x * 2e7  # mimick compute-intense training\n",
    "    while n > 0:\n",
    "        n -= 1\n",
    "    y = x ** 2\n",
    "    print(f'training with {x} end')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbd0df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [1, 8, 1.5, 2]  # some dummy simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7915f6",
   "metadata": {},
   "source": [
    "Again, first, we use the builtin `map` function to perform the number crunching serially for each item in l:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94296e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result = list(map(train_neural_network, input_data))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67728128",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- number crunching causes high CPU load (surprise! ;) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e052056",
   "metadata": {},
   "source": [
    "# Parallel processes\n",
    "For such tasks, we use the `ProcessPool`. In contrast to the `ThreadPool` this distributes work across multiple processes running separate instances of the Python interpreter. This allows you to circumvent the limitations of the GIL and achieve truly parallel code execution. For use cases which are **compute bound**, it is an excellent, simple-to-use option. As already introduced above, these use cases may include numerical simulations, sampling methods etc. Unfortunately, using multiple processes introduces some downsides, such as some overhead (time & memory) for launching processes and increased memory consumption (e.g., duplication of data; warning: depends on implementation and use case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206b29e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import Pool as ProcessPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185c4660",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with ProcessPool(processes=2) as pool:  # context manager providing a `Pool` instance\n",
    "    result = pool.map(train_neural_network, input_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931a8a95",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c0af36",
   "metadata": {},
   "source": [
    "Observations?\n",
    "- results are identical to serial and threaded execution; good!\n",
    "- runtime is reduced compared to both serial and threaded execution\n",
    "- increased CPU load on multiple cores\n",
    "- caveat: as before, no automatic load balancing, tasks are executed in order\n",
    "\n",
    "Questions:\n",
    "- What is the fundamental difference between threads and processes? -> memory shared across threads, by default not across processes\n",
    "- How is data communicated between threads? -> shared memory (direct access)\n",
    "- How is data communicated between processes? -> sending serialized data from one process to the other (in Python: `pickle` -> problems with stuff that's not picklable), or set up shared memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ff1be9",
   "metadata": {},
   "source": [
    "### Parallel speedup\n",
    "\n",
    "So how much faster does my code become when I'm increasing the number of processes? Here we investigate the relative speedup ($T_\\textrm{parallel} / T_\\textrm{serial}$) for an increasing number of processes. We use the same compute-bound function as before, but remove some of the annoying output and make it a bit shorter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed805b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train_neural_network(x):\n",
    "    \"\"\"Train your favourite neural network model.\"\"\"\n",
    "    n = x * 2e6  # mimick compute-intense training\n",
    "    while n > 0:\n",
    "        n -= 1\n",
    "    y = x ** 2\n",
    "    return y\n",
    "\n",
    "\n",
    "input_data = [2] * 16  # some dummy simulations of equal duration\n",
    "times = []\n",
    "n_processes = np.arange(1, multiprocessing.cpu_count() + 4)\n",
    "for n in n_processes:\n",
    "    t0 = time.time()\n",
    "    with ProcessPool(processes=n) as pool:\n",
    "        result = pool.map(train_neural_network, input_data)\n",
    "    times.append(time.time() - t0)\n",
    "\n",
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7239413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "times = np.array(times)\n",
    "fig, axes = plt.subplots()\n",
    "axes.plot(n_processes, 1.0 * n_processes, color='k', linestyle='--', label='ideal')\n",
    "axes.plot(n_processes, times[0] / times, marker='o', label='measured')\n",
    "axes.set_xlabel(r'$n$ processes')\n",
    "axes.set_ylabel('relative speedup')\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd68ac4",
   "metadata": {},
   "source": [
    "Observations\n",
    "- perfect speedup up to X processes, (on some machines) good speedup until ~Y processes with decreasing benefits\n",
    "- no (significant) benefits for more processes\n",
    "- rule of thumb: benefits up to number of cores (OS also needs some compute: context switching; also hyperthreading does not seem to work well in my experience)\n",
    "\n",
    "Questions:\n",
    "- Can we combine `ProcessPools` with `ThreadPools` in the worker processes? -> yes, but benefit depends on use case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced84a2d",
   "metadata": {},
   "source": [
    "## Resources\n",
    "https://www.youtube.com/watch?v=AG1soUh4-nU"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
